{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest and Deep Learning using h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading file\n",
    "url=\"https://raw.githubusercontent.com/rajsiddarth/Datasets/master/Bank_dataset.csv\"\n",
    "import pandas as pd\n",
    "data=pd.read_csv(url,header=0,names=[\"id\",\"age\",\"experience\",\"income\",\"zipcode\",\"family\"\n",
    "             ,\"ccavg\",\"education\",\"mortgage\",\"pers_loan\",\"sec_amount\",\"cd_account\",\"online\",\"credit_card\"])\n",
    "#Removing id,zipcode and experience\n",
    "data.drop(['id','experience','zipcode'],inplace=True,axis=1)\n",
    "categ_data=data.loc[:,['education','sec_amount','cd_account','online','credit_card']]\n",
    "dep_data=pd.DataFrame(data.loc[:,'pers_loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family</th>\n",
       "      <th>ccavg</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>education</th>\n",
       "      <th>sec_amount</th>\n",
       "      <th>cd_account</th>\n",
       "      <th>online</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>pers_loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  family  ccavg  mortgage education sec_amount cd_account  \\\n",
       "0   25      49       4    1.6         0         1          1          0   \n",
       "1   45      34       3    1.5         0         1          1          0   \n",
       "2   39      11       1    1.0         0         1          0          0   \n",
       "3   35     100       1    2.7         0         2          0          0   \n",
       "4   35      45       4    1.0         0         2          0          0   \n",
       "\n",
       "  online credit_card pers_loan  \n",
       "0      0           0         0  \n",
       "1      0           0         0  \n",
       "2      0           0         0  \n",
       "3      0           0         0  \n",
       "4      0           1         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to factors\n",
    "\n",
    "for i in categ_data.columns:\n",
    "    categ_data[i]= categ_data[i].astype('category')\n",
    "dep_data['pers_loan']=dep_data['pers_loan'].astype('category')\n",
    "data.drop(['education','pers_loan','sec_amount','cd_account','online','credit_card'],inplace=True,axis=1)\n",
    "data=pd.concat([data,categ_data,dep_data],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               int64\n",
      "income            int64\n",
      "family            int64\n",
      "ccavg           float64\n",
      "mortgage          int64\n",
      "education      category\n",
      "sec_amount     category\n",
      "cd_account     category\n",
      "online         category\n",
      "credit_card    category\n",
      "pers_loan      category\n",
      "dtype: object\n",
      "(5000, 11)\n"
     ]
    }
   ],
   "source": [
    "print data.dtypes\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test data using Stratified sampling based on target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3164\n",
      "1     336\n",
      "Name: pers_loan, dtype: int64 0    1356\n",
      "1     144\n",
      "Name: pers_loan, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sid\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "X=data.loc[:,data.columns.difference(['pers_loan'])]\n",
    "Y=data.loc[:,'pers_loan']\n",
    "index=StratifiedShuffleSplit(Y,n_iter=1,random_state=42,test_size=0.3)\n",
    "for trainindex,testindex in index:\n",
    "    X_train,X_test=X.loc[trainindex],X.loc[testindex]\n",
    "    y_train,y_test=Y.loc[trainindex],Y.loc[testindex]\n",
    "print y_train.value_counts(),y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model=rf(n_estimators=50,criterion=\"gini\",random_state=42,verbose=0)\n",
    "\n",
    "#Fitting the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Predicting using the model on train data\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print (accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance=model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAJNCAYAAAD+jxwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb0ae400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting variable importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6 * 1.618, 6))\n",
    "index = np.arange(len(X_train.columns.values))\n",
    "bar_width = 0.35\n",
    "plt.bar(index,importance, color='b', alpha=0.5)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('importance')\n",
    "plt.title('Feature importance')\n",
    "plt.xticks(index,X_train.columns)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Deep learning using h2o platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (Zulu 8.20.0.5-win64) (build 25.121-b15, mixed mode)\n",
      "  Starting server from C:\\Users\\sid\\Anaconda2\\h2o_jar\\h2o.jar\n",
      "  Ice root: c:\\users\\sid\\appdata\\local\\temp\\tmps9opie\n",
      "  JVM stdout: c:\\users\\sid\\appdata\\local\\temp\\tmps9opie\\h2o_sid_started_from_python.out\n",
      "  JVM stderr: c:\\users\\sid\\appdata\\local\\temp\\tmps9opie\\h2o_sid_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (7 months and 3 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.0.9</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>7 months and 3 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_sid_ld91oq</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>910 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         05 secs\n",
       "H2O cluster version:        3.10.0.9\n",
       "H2O cluster version age:    7 months and 3 days !!!\n",
       "H2O cluster name:           H2O_from_python_sid_ld91oq\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    910 Mb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(nthreads = -1, max_mem_size = \"1g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding data frames to h20 and building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "y_train,y_test=pd.DataFrame(y_train),pd.DataFrame(y_test)\n",
    "train_data,test_data=pd.concat([X_train,y_train],axis=1),pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "#Importing H2OFrame to import python object into h2o\n",
    "from h2o.frame import H2OFrame\n",
    "train_data,test_data= H2OFrame(train_data),H2OFrame(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train deep autoencoder learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">  ccavg</th><th style=\"text-align: right;\">  cd_account</th><th style=\"text-align: right;\">  credit_card</th><th style=\"text-align: right;\">  education</th><th style=\"text-align: right;\">  family</th><th style=\"text-align: right;\">  income</th><th style=\"text-align: right;\">  mortgage</th><th style=\"text-align: right;\">  online</th><th style=\"text-align: right;\">  sec_amount</th><th style=\"text-align: right;\">  pers_loan</th></tr>\n",
       "<tr><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">   2.67</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      81</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">   1   </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      31</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   56</td><td style=\"text-align: right;\">   3.7 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">      65</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">   7.3 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">     155</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\">   2.8 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       3</td><td style=\"text-align: right;\">      58</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       3</td><td style=\"text-align: right;\">      74</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   47</td><td style=\"text-align: right;\">   0.8 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">      93</td><td style=\"text-align: right;\">       107</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   55</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   53</td><td style=\"text-align: right;\">   0.5 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      22</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">   3.5 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">     115</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pers_loan': u'enum'}\n",
      "{'ccavg': u'real', 'mortgage': u'int', 'family': u'int', 'income': u'int', 'age': u'int', 'sec_amount': u'int', u'credit_card': u'enum'}\n"
     ]
    }
   ],
   "source": [
    "#Preparing train and test sets\n",
    "y_train,y_test=train_data['pers_loan'].asfactor(),test_data['pers_loan'].asfactor()\n",
    "categ_data1,categ_data2=train_data.drop(['age','ccavg','pers_loan','family','income','mortgage','sec_amount']).asfactor(),test_data.drop(['age','ccavg','sec_amount','pers_loan','family','income','mortgage']).asfactor()\n",
    "temp_data1,temp_data2=train_data[['age','ccavg','family','income','mortgage','sec_amount']],test_data[['age','sec_amount','ccavg','family','income','mortgage']]\n",
    "\n",
    "#Concatanate categorical ad numeric data\n",
    "data1,data2=categ_data1.concat([temp_data1],axis=1),categ_data2.concat([temp_data2],axis=1)\n",
    "train,test=data1.concat([y_train],axis=1),data2.concat([y_test],axis=1),\n",
    "X_train,X_test=data1,data2\n",
    "print y_train.types\n",
    "print X_train.types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building DeepLearning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "model = H2ODeepLearningEstimator(distribution=\"multinomial\",activation=\"tanh_with_dropout\",hidden=[50,50,50],sparse=True,l1=1e-4,epochs=100,\n",
    "                                input_dropout_ratio=0.1,variable_importances=True,nfolds=5)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "model.train(x=data1.columns,y=\"pers_loan\",training_frame=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1496736115661_10\n",
      "Status of Neuron Layers: predicting pers_loan, 2-class classification, multinomial distribution, CrossEntropy loss, 6,202 weights/biases, 79.3 KB, 385,000 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>19</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2117783</td>\n",
       "<td>0.4102108</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0376196</td>\n",
       "<td>1.1713943</td>\n",
       "<td>0.0020606</td>\n",
       "<td>1.1227937</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0094161</td>\n",
       "<td>0.0214251</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0032480</td>\n",
       "<td>0.5070341</td>\n",
       "<td>-0.0118283</td>\n",
       "<td>1.2967100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0508906</td>\n",
       "<td>0.1332909</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0016964</td>\n",
       "<td>0.1918201</td>\n",
       "<td>0.0292983</td>\n",
       "<td>0.4668208</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0193523</td>\n",
       "<td>0.1176573</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0234441</td>\n",
       "<td>0.4128304</td>\n",
       "<td>-0.0130815</td>\n",
       "<td>0.9297132</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type         dropout    l1      l2    mean_rate         rate_rms         momentum    mean_weight        weight_rms      mean_bias         bias_rms\n",
       "--  -------  -------  -----------  ---------  ------  ----  ----------------  ---------------  ----------  -----------------  --------------  ----------------  --------------\n",
       "    1        19       Input        10.0\n",
       "    2        50       TanhDropout  50.0       0.0001  0.0   0.211778286684    0.410210847855   0.0         0.0376195660461    1.17139434814   0.00206062811495  1.12279367447\n",
       "    3        50       TanhDropout  50.0       0.0001  0.0   0.00941606880827  0.0214250609279  0.0         -0.00324799562058  0.507034063339  -0.0118282645905  1.29671001434\n",
       "    4        50       TanhDropout  50.0       0.0001  0.0   0.0508905532768   0.133290946484   0.0         -0.00169639947334  0.191820085049  0.029298252369    0.466820836067\n",
       "    5        2        Softmax                 0.0001  0.0   0.0193523469602   0.117657274008   0.0         -0.0234440551466   0.412830352783  -0.0130814714363  0.929713249207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0374867531657\n",
      "RMSE: 0.19361496111\n",
      "LogLoss: 0.134131204218\n",
      "Mean Per-Class Error: 0.0847687526338\n",
      "AUC: 0.970069720366\n",
      "Gini: 0.940139440732\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30876653834: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>3113.0</td>\n",
       "<td>51.0</td>\n",
       "<td>0.0161</td>\n",
       "<td> (51.0/3164.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>79.0</td>\n",
       "<td>257.0</td>\n",
       "<td>0.2351</td>\n",
       "<td> (79.0/336.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3192.0</td>\n",
       "<td>308.0</td>\n",
       "<td>0.0371</td>\n",
       "<td> (130.0/3500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      3113  51   0.0161   (51.0/3164.0)\n",
       "1      79    257  0.2351   (79.0/336.0)\n",
       "Total  3192  308  0.0371   (130.0/3500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7981366</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.8164937</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4623582</td>\n",
       "<td>0.8308157</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3156085</td>\n",
       "<td>0.9628571</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.6581360</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0124035</td>\n",
       "<td>1.0</td>\n",
       "<td>392.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.6581360</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7786189</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0736977</td>\n",
       "<td>0.9086599</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.9152312</td>\n",
       "<td>242.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.308767     0.798137  146\n",
       "max f2                       0.0962572    0.816494  242\n",
       "max f0point5                 0.462358     0.830816  100\n",
       "max accuracy                 0.315608     0.962857  144\n",
       "max precision                0.658136     1         0\n",
       "max recall                   0.0124035    1         392\n",
       "max specificity              0.658136     1         0\n",
       "max absolute_mcc             0.308767     0.778619  146\n",
       "max min_per_class_accuracy   0.0736977    0.90866   269\n",
       "max mean_per_class_accuracy  0.0962572    0.915231  242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.6563358</td>\n",
       "<td>10.4166667</td>\n",
       "<td>10.4166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1041667</td>\n",
       "<td>0.1041667</td>\n",
       "<td>941.6666667</td>\n",
       "<td>941.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6523158</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.8214286</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.1964286</td>\n",
       "<td>822.6190476</td>\n",
       "<td>882.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6390291</td>\n",
       "<td>8.6309524</td>\n",
       "<td>9.4246032</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.9047619</td>\n",
       "<td>0.0863095</td>\n",
       "<td>0.2827381</td>\n",
       "<td>763.0952381</td>\n",
       "<td>842.4603175</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6292032</td>\n",
       "<td>10.1190476</td>\n",
       "<td>9.5982143</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9214286</td>\n",
       "<td>0.1011905</td>\n",
       "<td>0.3839286</td>\n",
       "<td>911.9047619</td>\n",
       "<td>859.8214286</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.6063924</td>\n",
       "<td>8.9285714</td>\n",
       "<td>9.4642857</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9085714</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.4732143</td>\n",
       "<td>792.8571429</td>\n",
       "<td>846.4285714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.1960377</td>\n",
       "<td>6.4880952</td>\n",
       "<td>7.9761905</td>\n",
       "<td>0.6228571</td>\n",
       "<td>0.7657143</td>\n",
       "<td>0.3244048</td>\n",
       "<td>0.7976190</td>\n",
       "<td>548.8095238</td>\n",
       "<td>697.6190476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0842467</td>\n",
       "<td>1.9642857</td>\n",
       "<td>5.9722222</td>\n",
       "<td>0.1885714</td>\n",
       "<td>0.5733333</td>\n",
       "<td>0.0982143</td>\n",
       "<td>0.8958333</td>\n",
       "<td>96.4285714</td>\n",
       "<td>497.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0588496</td>\n",
       "<td>0.8928571</td>\n",
       "<td>4.7023810</td>\n",
       "<td>0.0857143</td>\n",
       "<td>0.4514286</td>\n",
       "<td>0.0446429</td>\n",
       "<td>0.9404762</td>\n",
       "<td>-10.7142857</td>\n",
       "<td>370.2380952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0342866</td>\n",
       "<td>0.1785714</td>\n",
       "<td>3.1944444</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.3066667</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9583333</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>219.4444444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0215800</td>\n",
       "<td>0.2083333</td>\n",
       "<td>2.4479167</td>\n",
       "<td>0.02</td>\n",
       "<td>0.235</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-79.1666667</td>\n",
       "<td>144.7916667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0126327</td>\n",
       "<td>0.1785714</td>\n",
       "<td>1.9940476</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.1914286</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9970238</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>99.4047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0118444</td>\n",
       "<td>0.0297619</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0028571</td>\n",
       "<td>0.16</td>\n",
       "<td>0.0029762</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.0238095</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0118066</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1371429</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0117779</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0117396</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0116798</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.656336           10.4167    10.4167            1                1                           0.104167        0.104167                   941.667   941.667\n",
       "    2        0.02                        0.652316           9.22619    9.82143            0.885714         0.942857                    0.0922619       0.196429                   822.619   882.143\n",
       "    3        0.03                        0.639029           8.63095    9.4246             0.828571         0.904762                    0.0863095       0.282738                   763.095   842.46\n",
       "    4        0.04                        0.629203           10.119     9.59821            0.971429         0.921429                    0.10119         0.383929                   911.905   859.821\n",
       "    5        0.05                        0.606392           8.92857    9.46429            0.857143         0.908571                    0.0892857       0.473214                   792.857   846.429\n",
       "    6        0.1                         0.196038           6.4881     7.97619            0.622857         0.765714                    0.324405        0.797619                   548.81    697.619\n",
       "    7        0.15                        0.0842467          1.96429    5.97222            0.188571         0.573333                    0.0982143       0.895833                   96.4286   497.222\n",
       "    8        0.2                         0.0588496          0.892857   4.70238            0.0857143        0.451429                    0.0446429       0.940476                   -10.7143  370.238\n",
       "    9        0.3                         0.0342866          0.178571   3.19444            0.0171429        0.306667                    0.0178571       0.958333                   -82.1429  219.444\n",
       "    10       0.4                         0.02158            0.208333   2.44792            0.02             0.235                       0.0208333       0.979167                   -79.1667  144.792\n",
       "    11       0.5                         0.0126327          0.178571   1.99405            0.0171429        0.191429                    0.0178571       0.997024                   -82.1429  99.4048\n",
       "    12       0.6                         0.0118444          0.0297619  1.66667            0.00285714       0.16                        0.00297619      1                          -97.0238  66.6667\n",
       "    13       0.7                         0.0118066          0          1.42857            0                0.137143                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0117779          0          1.25               0                0.12                        0               1                          -100      25\n",
       "    15       0.9                         0.0117396          0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0116798          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0376753629732\n",
      "RMSE: 0.194101424449\n",
      "LogLoss: 0.135341518619\n",
      "Mean Per-Class Error: 0.0929203539823\n",
      "AUC: 0.9607324401\n",
      "Gini: 0.9214648802\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.388100194917: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>3094.0</td>\n",
       "<td>70.0</td>\n",
       "<td>0.0221</td>\n",
       "<td> (70.0/3164.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>73.0</td>\n",
       "<td>263.0</td>\n",
       "<td>0.2173</td>\n",
       "<td> (73.0/336.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3167.0</td>\n",
       "<td>333.0</td>\n",
       "<td>0.0409</td>\n",
       "<td> (143.0/3500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      3094  70   0.0221   (70.0/3164.0)\n",
       "1      73    263  0.2173   (73.0/336.0)\n",
       "Total  3167  333  0.0409   (143.0/3500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.7862481</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2383975</td>\n",
       "<td>0.7948140</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5007413</td>\n",
       "<td>0.8005618</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.9591429</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7798890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0106412</td>\n",
       "<td>1.0</td>\n",
       "<td>391.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7798890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.7636708</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1079401</td>\n",
       "<td>0.9039191</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0839398</td>\n",
       "<td>0.9070796</td>\n",
       "<td>301.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.3881       0.786248  153\n",
       "max f2                       0.238397     0.794814  212\n",
       "max f0point5                 0.500741     0.800562  115\n",
       "max accuracy                 0.3881       0.959143  153\n",
       "max precision                0.779889     1         0\n",
       "max recall                   0.0106412    1         391\n",
       "max specificity              0.779889     1         0\n",
       "max absolute_mcc             0.3881       0.763671  153\n",
       "max min_per_class_accuracy   0.10794      0.903919  284\n",
       "max mean_per_class_accuracy  0.0839398    0.90708   301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.7334891</td>\n",
       "<td>9.8214286</td>\n",
       "<td>9.8214286</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.0982143</td>\n",
       "<td>0.0982143</td>\n",
       "<td>882.1428571</td>\n",
       "<td>882.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6928595</td>\n",
       "<td>8.9285714</td>\n",
       "<td>9.375</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.1875</td>\n",
       "<td>792.8571429</td>\n",
       "<td>837.5</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6479753</td>\n",
       "<td>8.3333333</td>\n",
       "<td>9.0277778</td>\n",
       "<td>0.8</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.2708333</td>\n",
       "<td>733.3333333</td>\n",
       "<td>802.7777778</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6220193</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.0773810</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8714286</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.3630952</td>\n",
       "<td>822.6190476</td>\n",
       "<td>807.7380952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.5970436</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.1071429</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8742857</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.4553571</td>\n",
       "<td>822.6190476</td>\n",
       "<td>810.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3399548</td>\n",
       "<td>6.7261905</td>\n",
       "<td>7.9166667</td>\n",
       "<td>0.6457143</td>\n",
       "<td>0.76</td>\n",
       "<td>0.3363095</td>\n",
       "<td>0.7916667</td>\n",
       "<td>572.6190476</td>\n",
       "<td>691.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.1530605</td>\n",
       "<td>1.7261905</td>\n",
       "<td>5.8531746</td>\n",
       "<td>0.1657143</td>\n",
       "<td>0.5619048</td>\n",
       "<td>0.0863095</td>\n",
       "<td>0.8779762</td>\n",
       "<td>72.6190476</td>\n",
       "<td>485.3174603</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0737658</td>\n",
       "<td>1.0119048</td>\n",
       "<td>4.6428571</td>\n",
       "<td>0.0971429</td>\n",
       "<td>0.4457143</td>\n",
       "<td>0.0505952</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.1904762</td>\n",
       "<td>364.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0289900</td>\n",
       "<td>0.2678571</td>\n",
       "<td>3.1845238</td>\n",
       "<td>0.0257143</td>\n",
       "<td>0.3057143</td>\n",
       "<td>0.0267857</td>\n",
       "<td>0.9553571</td>\n",
       "<td>-73.2142857</td>\n",
       "<td>218.4523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0138734</td>\n",
       "<td>0.1488095</td>\n",
       "<td>2.4255952</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.2328571</td>\n",
       "<td>0.0148810</td>\n",
       "<td>0.9702381</td>\n",
       "<td>-85.1190476</td>\n",
       "<td>142.5595238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0127652</td>\n",
       "<td>0.0892857</td>\n",
       "<td>1.9583333</td>\n",
       "<td>0.0085714</td>\n",
       "<td>0.188</td>\n",
       "<td>0.0089286</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-91.0714286</td>\n",
       "<td>95.8333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0116401</td>\n",
       "<td>0.0595238</td>\n",
       "<td>1.6418651</td>\n",
       "<td>0.0057143</td>\n",
       "<td>0.1576190</td>\n",
       "<td>0.0059524</td>\n",
       "<td>0.9851190</td>\n",
       "<td>-94.0476190</td>\n",
       "<td>64.1865079</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0110488</td>\n",
       "<td>0.1190476</td>\n",
       "<td>1.4243197</td>\n",
       "<td>0.0114286</td>\n",
       "<td>0.1367347</td>\n",
       "<td>0.0119048</td>\n",
       "<td>0.9970238</td>\n",
       "<td>-88.0952381</td>\n",
       "<td>42.4319728</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0095469</td>\n",
       "<td>0.0297619</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0028571</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0029762</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.0238095</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0077356</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0073608</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.733489           9.82143    9.82143            0.942857         0.942857                    0.0982143       0.0982143                  882.143   882.143\n",
       "    2        0.02                        0.69286            8.92857    9.375              0.857143         0.9                         0.0892857       0.1875                     792.857   837.5\n",
       "    3        0.03                        0.647975           8.33333    9.02778            0.8              0.866667                    0.0833333       0.270833                   733.333   802.778\n",
       "    4        0.04                        0.622019           9.22619    9.07738            0.885714         0.871429                    0.0922619       0.363095                   822.619   807.738\n",
       "    5        0.05                        0.597044           9.22619    9.10714            0.885714         0.874286                    0.0922619       0.455357                   822.619   810.714\n",
       "    6        0.1                         0.339955           6.72619    7.91667            0.645714         0.76                        0.33631         0.791667                   572.619   691.667\n",
       "    7        0.15                        0.153061           1.72619    5.85317            0.165714         0.561905                    0.0863095       0.877976                   72.619    485.317\n",
       "    8        0.2                         0.0737658          1.0119     4.64286            0.0971429        0.445714                    0.0505952       0.928571                   1.19048   364.286\n",
       "    9        0.3                         0.02899            0.267857   3.18452            0.0257143        0.305714                    0.0267857       0.955357                   -73.2143  218.452\n",
       "    10       0.4                         0.0138734          0.14881    2.4256             0.0142857        0.232857                    0.014881        0.970238                   -85.119   142.56\n",
       "    11       0.5                         0.0127652          0.0892857  1.95833            0.00857143       0.188                       0.00892857      0.979167                   -91.0714  95.8333\n",
       "    12       0.6                         0.0116401          0.0595238  1.64187            0.00571429       0.157619                    0.00595238      0.985119                   -94.0476  64.1865\n",
       "    13       0.7                         0.0110488          0.119048   1.42432            0.0114286        0.136735                    0.0119048       0.997024                   -88.0952  42.432\n",
       "    14       0.8                         0.00954687         0.0297619  1.25               0.00285714       0.12                        0.00297619      1                          -97.0238  25\n",
       "    15       0.9                         0.00773562         0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0073608          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9624398</td>\n",
       "<td>0.0045850</td>\n",
       "<td>0.9733893</td>\n",
       "<td>0.9562683</td>\n",
       "<td>0.9602357</td>\n",
       "<td>0.965847</td>\n",
       "<td>0.9564586</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9661146</td>\n",
       "<td>0.0069172</td>\n",
       "<td>0.9723753</td>\n",
       "<td>0.9467847</td>\n",
       "<td>0.9714912</td>\n",
       "<td>0.9718502</td>\n",
       "<td>0.968072</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0375602</td>\n",
       "<td>0.0045850</td>\n",
       "<td>0.0266106</td>\n",
       "<td>0.0437318</td>\n",
       "<td>0.0397644</td>\n",
       "<td>0.0341530</td>\n",
       "<td>0.0435414</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>26.2</td>\n",
       "<td>2.8774989</td>\n",
       "<td>19.0</td>\n",
       "<td>30.0</td>\n",
       "<td>27.0</td>\n",
       "<td>25.0</td>\n",
       "<td>30.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.8141792</td>\n",
       "<td>0.0242135</td>\n",
       "<td>0.875</td>\n",
       "<td>0.7836990</td>\n",
       "<td>0.8288044</td>\n",
       "<td>0.7939189</td>\n",
       "<td>0.7894737</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7965801</td>\n",
       "<td>0.0261990</td>\n",
       "<td>0.8549618</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.8187919</td>\n",
       "<td>0.789916</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7800731</td>\n",
       "<td>0.0298707</td>\n",
       "<td>0.8358209</td>\n",
       "<td>0.755287</td>\n",
       "<td>0.8090186</td>\n",
       "<td>0.7859532</td>\n",
       "<td>0.7142857</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>9.936483</td>\n",
       "<td>1.069964</td>\n",
       "<td>10.5</td>\n",
       "<td>10.238806</td>\n",
       "<td>7.6578946</td>\n",
       "<td>12.2</td>\n",
       "<td>9.085714</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.1356553</td>\n",
       "<td>0.0087051</td>\n",
       "<td>0.1311911</td>\n",
       "<td>0.1511206</td>\n",
       "<td>0.1465405</td>\n",
       "<td>0.1163249</td>\n",
       "<td>0.1330990</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2303859</td>\n",
       "<td>0.0327208</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.2537313</td>\n",
       "<td>0.1973684</td>\n",
       "<td>0.2166667</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.7768043</td>\n",
       "<td>0.0278982</td>\n",
       "<td>0.8410789</td>\n",
       "<td>0.7455322</td>\n",
       "<td>0.7966734</td>\n",
       "<td>0.7713623</td>\n",
       "<td>0.729375</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8762450</td>\n",
       "<td>0.0167753</td>\n",
       "<td>0.9063467</td>\n",
       "<td>0.8626335</td>\n",
       "<td>0.8913655</td>\n",
       "<td>0.8827381</td>\n",
       "<td>0.838141</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1237550</td>\n",
       "<td>0.0167753</td>\n",
       "<td>0.0936533</td>\n",
       "<td>0.1373665</td>\n",
       "<td>0.1086345</td>\n",
       "<td>0.1172619</td>\n",
       "<td>0.1618590</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0377755</td>\n",
       "<td>0.0025824</td>\n",
       "<td>0.0363035</td>\n",
       "<td>0.0407072</td>\n",
       "<td>0.0421197</td>\n",
       "<td>0.0316946</td>\n",
       "<td>0.0380525</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.8265896</td>\n",
       "<td>0.0245298</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.7936508</td>\n",
       "<td>0.8356164</td>\n",
       "<td>0.7966102</td>\n",
       "<td>0.8181818</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5652950</td>\n",
       "<td>0.0115579</td>\n",
       "<td>0.5786878</td>\n",
       "<td>0.5380936</td>\n",
       "<td>0.5762654</td>\n",
       "<td>0.5788015</td>\n",
       "<td>0.5546271</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7696142</td>\n",
       "<td>0.0327208</td>\n",
       "<td>0.8235294</td>\n",
       "<td>0.7462686</td>\n",
       "<td>0.8026316</td>\n",
       "<td>0.7833334</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1941252</td>\n",
       "<td>0.0067415</td>\n",
       "<td>0.1905349</td>\n",
       "<td>0.2017602</td>\n",
       "<td>0.2052308</td>\n",
       "<td>0.1780298</td>\n",
       "<td>0.1950705</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9828758</td>\n",
       "<td>0.0025304</td>\n",
       "<td>0.9891641</td>\n",
       "<td>0.9789984</td>\n",
       "<td>0.9800995</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9839743</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.96244    0.00458501  0.973389      0.956268      0.960236      0.965847      0.956459\n",
       "auc                      0.966115   0.00691722  0.972375      0.946785      0.971491      0.97185       0.968072\n",
       "err                      0.0375602  0.00458501  0.0266106     0.0437318     0.0397644     0.034153      0.0435414\n",
       "err_count                26.2       2.8775      19            30            27            25            30\n",
       "f0point5                 0.814179   0.0242135   0.875         0.783699      0.828804      0.793919      0.789474\n",
       "f1                       0.79658    0.026199    0.854962      0.769231      0.818792      0.789916      0.75\n",
       "f2                       0.780073   0.0298707   0.835821      0.755287      0.809019      0.785953      0.714286\n",
       "lift_top_group           9.93648    1.06996     10.5          10.2388       7.65789       12.2          9.08571\n",
       "logloss                  0.135655   0.00870512  0.131191      0.151121      0.146541      0.116325      0.133099\n",
       "max_per_class_error      0.230386   0.0327208   0.176471      0.253731      0.197368      0.216667      0.307692\n",
       "mcc                      0.776804   0.0278982   0.841079      0.745532      0.796673      0.771362      0.729375\n",
       "mean_per_class_accuracy  0.876245   0.0167753   0.906347      0.862634      0.891366      0.882738      0.838141\n",
       "mean_per_class_error     0.123755   0.0167753   0.0936533     0.137366      0.108634      0.117262      0.161859\n",
       "mse                      0.0377755  0.0025824   0.0363035     0.0407072     0.0421197     0.0316946     0.0380525\n",
       "precision                0.82659    0.0245298   0.888889      0.793651      0.835616      0.79661       0.818182\n",
       "r2                       0.565295   0.0115579   0.578688      0.538094      0.576265      0.578801      0.554627\n",
       "recall                   0.769614   0.0327208   0.823529      0.746269      0.802632      0.783333      0.692308\n",
       "rmse                     0.194125   0.00674149  0.190535      0.20176       0.205231      0.17803       0.195071\n",
       "specificity              0.982876   0.00253039  0.989164      0.978998      0.9801        0.982143      0.983974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:25</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:27</td>\n",
       "<td>51.888 sec</td>\n",
       "<td>28340 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>35000.0</td>\n",
       "<td>0.2046760</td>\n",
       "<td>0.1459836</td>\n",
       "<td>0.9594122</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.0491429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:33</td>\n",
       "<td>58.038 sec</td>\n",
       "<td>28649 obs/sec</td>\n",
       "<td>60.0</td>\n",
       "<td>6</td>\n",
       "<td>210000.0</td>\n",
       "<td>0.1992744</td>\n",
       "<td>0.1417528</td>\n",
       "<td>0.9661853</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.034</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:39</td>\n",
       "<td> 1 min  4.120 sec</td>\n",
       "<td>28819 obs/sec</td>\n",
       "<td>110.0</td>\n",
       "<td>11</td>\n",
       "<td>385000.0</td>\n",
       "<td>0.1936150</td>\n",
       "<td>0.1341312</td>\n",
       "<td>0.9700697</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.0371429</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2017-06-06 14:16:25  0.000 sec                           0         0             0          nan              nan                 nan             nan              nan\n",
       "    2017-06-06 14:16:27  51.888 sec        28340 obs/sec     10        1             35000      0.204676         0.145984            0.959412        10.4167          0.0491429\n",
       "    2017-06-06 14:16:33  58.038 sec        28649 obs/sec     60        6             210000     0.199274         0.141753            0.966185        10.4167          0.034\n",
       "    2017-06-06 14:16:39  1 min  4.120 sec  28819 obs/sec     110       11            385000     0.193615         0.134131            0.97007         10.4167          0.0371429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>cd_account.1</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2904788</td></tr>\n",
       "<tr><td>income</td>\n",
       "<td>0.3277385</td>\n",
       "<td>0.3277385</td>\n",
       "<td>0.0952011</td></tr>\n",
       "<tr><td>education.2</td>\n",
       "<td>0.3205053</td>\n",
       "<td>0.3205053</td>\n",
       "<td>0.0931000</td></tr>\n",
       "<tr><td>education.3</td>\n",
       "<td>0.3178874</td>\n",
       "<td>0.3178874</td>\n",
       "<td>0.0923395</td></tr>\n",
       "<tr><td>cd_account.0</td>\n",
       "<td>0.2599115</td>\n",
       "<td>0.2599115</td>\n",
       "<td>0.0754988</td></tr>\n",
       "<tr><td>credit_card.1</td>\n",
       "<td>0.2311025</td>\n",
       "<td>0.2311025</td>\n",
       "<td>0.0671304</td></tr>\n",
       "<tr><td>ccavg</td>\n",
       "<td>0.2152246</td>\n",
       "<td>0.2152246</td>\n",
       "<td>0.0625182</td></tr>\n",
       "<tr><td>online.1</td>\n",
       "<td>0.1669591</td>\n",
       "<td>0.1669591</td>\n",
       "<td>0.0484981</td></tr>\n",
       "<tr><td>education.1</td>\n",
       "<td>0.1054023</td>\n",
       "<td>0.1054023</td>\n",
       "<td>0.0306171</td></tr>\n",
       "<tr><td>credit_card.0</td>\n",
       "<td>0.1011096</td>\n",
       "<td>0.1011096</td>\n",
       "<td>0.0293702</td></tr>\n",
       "<tr><td>online.0</td>\n",
       "<td>0.0934615</td>\n",
       "<td>0.0934615</td>\n",
       "<td>0.0271486</td></tr>\n",
       "<tr><td>sec_amount</td>\n",
       "<td>0.0844852</td>\n",
       "<td>0.0844852</td>\n",
       "<td>0.0245411</td></tr>\n",
       "<tr><td>family</td>\n",
       "<td>0.0810655</td>\n",
       "<td>0.0810655</td>\n",
       "<td>0.0235478</td></tr>\n",
       "<tr><td>mortgage</td>\n",
       "<td>0.0698077</td>\n",
       "<td>0.0698077</td>\n",
       "<td>0.0202777</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>0.0679318</td>\n",
       "<td>0.0679318</td>\n",
       "<td>0.0197327</td></tr>\n",
       "<tr><td>education.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>credit_card.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>cd_account.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>online.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                 relative_importance    scaled_importance    percentage\n",
       "-----------------------  ---------------------  -------------------  ------------\n",
       "cd_account.1             1                      1                    0.290479\n",
       "income                   0.327738               0.327738             0.0952011\n",
       "education.2              0.320505               0.320505             0.0931\n",
       "education.3              0.317887               0.317887             0.0923395\n",
       "cd_account.0             0.259912               0.259912             0.0754988\n",
       "credit_card.1            0.231102               0.231102             0.0671304\n",
       "ccavg                    0.215225               0.215225             0.0625182\n",
       "online.1                 0.166959               0.166959             0.0484981\n",
       "education.1              0.105402               0.105402             0.0306171\n",
       "credit_card.0            0.10111                0.10111              0.0293702\n",
       "online.0                 0.0934615              0.0934615            0.0271486\n",
       "sec_amount               0.0844852              0.0844852            0.0245411\n",
       "family                   0.0810655              0.0810655            0.0235478\n",
       "mortgage                 0.0698077              0.0698077            0.0202777\n",
       "age                      0.0679318              0.0679318            0.0197327\n",
       "education.missing(NA)    0                      0                    0\n",
       "credit_card.missing(NA)  0                      0                    0\n",
       "cd_account.missing(NA)   0                      0                    0\n",
       "online.missing(NA)       0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0374867531657\n",
      "RMSE: 0.19361496111\n",
      "LogLoss: 0.134131204218\n",
      "Mean Per-Class Error: 0.0847687526338\n",
      "AUC: 0.970040560472\n",
      "Gini: 0.940081120944\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30876653834: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>3113.0</td>\n",
       "<td>51.0</td>\n",
       "<td>0.0161</td>\n",
       "<td> (51.0/3164.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>79.0</td>\n",
       "<td>257.0</td>\n",
       "<td>0.2351</td>\n",
       "<td> (79.0/336.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3192.0</td>\n",
       "<td>308.0</td>\n",
       "<td>0.0371</td>\n",
       "<td> (130.0/3500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      3113  51   0.0161   (51.0/3164.0)\n",
       "1      79    257  0.2351   (79.0/336.0)\n",
       "Total  3192  308  0.0371   (130.0/3500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7981366</td>\n",
       "<td>145.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.8164937</td>\n",
       "<td>240.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4623582</td>\n",
       "<td>0.8308157</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3156085</td>\n",
       "<td>0.9628571</td>\n",
       "<td>143.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.6578842</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0122631</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.6578842</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7786189</td>\n",
       "<td>145.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0736977</td>\n",
       "<td>0.9086599</td>\n",
       "<td>267.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.9152312</td>\n",
       "<td>240.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.308767     0.798137  145\n",
       "max f2                       0.0962572    0.816494  240\n",
       "max f0point5                 0.462358     0.830816  99\n",
       "max accuracy                 0.315608     0.962857  143\n",
       "max precision                0.657884     1         0\n",
       "max recall                   0.0122631    1         394\n",
       "max specificity              0.657884     1         0\n",
       "max absolute_mcc             0.308767     0.778619  145\n",
       "max min_per_class_accuracy   0.0736977    0.90866   267\n",
       "max mean_per_class_accuracy  0.0962572    0.915231  240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.6563358</td>\n",
       "<td>10.4166667</td>\n",
       "<td>10.4166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1041667</td>\n",
       "<td>0.1041667</td>\n",
       "<td>941.6666667</td>\n",
       "<td>941.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6523158</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.8214286</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.1964286</td>\n",
       "<td>822.6190476</td>\n",
       "<td>882.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6390291</td>\n",
       "<td>8.6309524</td>\n",
       "<td>9.4246032</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.9047619</td>\n",
       "<td>0.0863095</td>\n",
       "<td>0.2827381</td>\n",
       "<td>763.0952381</td>\n",
       "<td>842.4603175</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6292032</td>\n",
       "<td>10.1190476</td>\n",
       "<td>9.5982143</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9214286</td>\n",
       "<td>0.1011905</td>\n",
       "<td>0.3839286</td>\n",
       "<td>911.9047619</td>\n",
       "<td>859.8214286</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.6063924</td>\n",
       "<td>8.9285714</td>\n",
       "<td>9.4642857</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9085714</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.4732143</td>\n",
       "<td>792.8571429</td>\n",
       "<td>846.4285714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.1960377</td>\n",
       "<td>6.4880952</td>\n",
       "<td>7.9761905</td>\n",
       "<td>0.6228571</td>\n",
       "<td>0.7657143</td>\n",
       "<td>0.3244048</td>\n",
       "<td>0.7976190</td>\n",
       "<td>548.8095238</td>\n",
       "<td>697.6190476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0842467</td>\n",
       "<td>1.9642857</td>\n",
       "<td>5.9722222</td>\n",
       "<td>0.1885714</td>\n",
       "<td>0.5733333</td>\n",
       "<td>0.0982143</td>\n",
       "<td>0.8958333</td>\n",
       "<td>96.4285714</td>\n",
       "<td>497.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0588496</td>\n",
       "<td>0.8928571</td>\n",
       "<td>4.7023810</td>\n",
       "<td>0.0857143</td>\n",
       "<td>0.4514286</td>\n",
       "<td>0.0446429</td>\n",
       "<td>0.9404762</td>\n",
       "<td>-10.7142857</td>\n",
       "<td>370.2380952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0342866</td>\n",
       "<td>0.1785714</td>\n",
       "<td>3.1944444</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.3066667</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9583333</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>219.4444444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0215800</td>\n",
       "<td>0.2083333</td>\n",
       "<td>2.4479167</td>\n",
       "<td>0.02</td>\n",
       "<td>0.235</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-79.1666667</td>\n",
       "<td>144.7916667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0126327</td>\n",
       "<td>0.1785714</td>\n",
       "<td>1.9940476</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.1914286</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9970238</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>99.4047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0118444</td>\n",
       "<td>0.0297619</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0028571</td>\n",
       "<td>0.16</td>\n",
       "<td>0.0029762</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.0238095</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0118066</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1371429</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0117779</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0117396</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0116798</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.656336           10.4167    10.4167            1                1                           0.104167        0.104167                   941.667   941.667\n",
       "    2        0.02                        0.652316           9.22619    9.82143            0.885714         0.942857                    0.0922619       0.196429                   822.619   882.143\n",
       "    3        0.03                        0.639029           8.63095    9.4246             0.828571         0.904762                    0.0863095       0.282738                   763.095   842.46\n",
       "    4        0.04                        0.629203           10.119     9.59821            0.971429         0.921429                    0.10119         0.383929                   911.905   859.821\n",
       "    5        0.05                        0.606392           8.92857    9.46429            0.857143         0.908571                    0.0892857       0.473214                   792.857   846.429\n",
       "    6        0.1                         0.196038           6.4881     7.97619            0.622857         0.765714                    0.324405        0.797619                   548.81    697.619\n",
       "    7        0.15                        0.0842467          1.96429    5.97222            0.188571         0.573333                    0.0982143       0.895833                   96.4286   497.222\n",
       "    8        0.2                         0.0588496          0.892857   4.70238            0.0857143        0.451429                    0.0446429       0.940476                   -10.7143  370.238\n",
       "    9        0.3                         0.0342866          0.178571   3.19444            0.0171429        0.306667                    0.0178571       0.958333                   -82.1429  219.444\n",
       "    10       0.4                         0.02158            0.208333   2.44792            0.02             0.235                       0.0208333       0.979167                   -79.1667  144.792\n",
       "    11       0.5                         0.0126327          0.178571   1.99405            0.0171429        0.191429                    0.0178571       0.997024                   -82.1429  99.4048\n",
       "    12       0.6                         0.0118444          0.0297619  1.66667            0.00285714       0.16                        0.00297619      1                          -97.0238  66.6667\n",
       "    13       0.7                         0.0118066          0          1.42857            0                0.137143                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0117779          0          1.25               0                0.12                        0               1                          -100      25\n",
       "    15       0.9                         0.0117396          0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0116798          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train data metrics\n",
    "model.model_performance(test_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0380405240371\n",
      "RMSE: 0.195039801162\n",
      "LogLoss: 0.135127026254\n",
      "Mean Per-Class Error: 0.0853306293019\n",
      "AUC: 0.969405522779\n",
      "Gini: 0.938811045559\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29787382422: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>1329.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0199</td>\n",
       "<td> (27.0/1356.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>32.0</td>\n",
       "<td>112.0</td>\n",
       "<td>0.2222</td>\n",
       "<td> (32.0/144.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1361.0</td>\n",
       "<td>139.0</td>\n",
       "<td>0.0393</td>\n",
       "<td> (59.0/1500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  -------------\n",
       "0      1329  27   0.0199   (27.0/1356.0)\n",
       "1      32    112  0.2222   (32.0/144.0)\n",
       "Total  1361  139  0.0393   (59.0/1500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2978738</td>\n",
       "<td>0.7915194</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2216687</td>\n",
       "<td>0.8071135</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4547315</td>\n",
       "<td>0.8219178</td>\n",
       "<td>83.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3089682</td>\n",
       "<td>0.9606667</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.6579125</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0127678</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.6579125</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2978738</td>\n",
       "<td>0.7699583</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0741780</td>\n",
       "<td>0.9107670</td>\n",
       "<td>211.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0865072</td>\n",
       "<td>0.9146694</td>\n",
       "<td>202.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.297874     0.791519  109\n",
       "max f2                       0.221669     0.807114  125\n",
       "max f0point5                 0.454731     0.821918  83\n",
       "max accuracy                 0.308968     0.960667  104\n",
       "max precision                0.657912     1         0\n",
       "max recall                   0.0127678    1         386\n",
       "max specificity              0.657912     1         0\n",
       "max absolute_mcc             0.297874     0.769958  109\n",
       "max min_per_class_accuracy   0.074178     0.910767  211\n",
       "max mean_per_class_accuracy  0.0865072    0.914669  202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.6559839</td>\n",
       "<td>10.4166667</td>\n",
       "<td>10.4166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1041667</td>\n",
       "<td>0.1041667</td>\n",
       "<td>941.6666667</td>\n",
       "<td>941.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6454479</td>\n",
       "<td>8.3333333</td>\n",
       "<td>9.375</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1875</td>\n",
       "<td>733.3333333</td>\n",
       "<td>837.5</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6359541</td>\n",
       "<td>9.7222222</td>\n",
       "<td>9.4907407</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9111111</td>\n",
       "<td>0.0972222</td>\n",
       "<td>0.2847222</td>\n",
       "<td>872.2222222</td>\n",
       "<td>849.0740741</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6277658</td>\n",
       "<td>8.3333333</td>\n",
       "<td>9.2013889</td>\n",
       "<td>0.8</td>\n",
       "<td>0.8833333</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.3680556</td>\n",
       "<td>733.3333333</td>\n",
       "<td>820.1388889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.6137297</td>\n",
       "<td>9.7222222</td>\n",
       "<td>9.3055556</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.8933333</td>\n",
       "<td>0.0972222</td>\n",
       "<td>0.4652778</td>\n",
       "<td>872.2222222</td>\n",
       "<td>830.5555556</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.2389537</td>\n",
       "<td>6.5277778</td>\n",
       "<td>7.9166667</td>\n",
       "<td>0.6266667</td>\n",
       "<td>0.76</td>\n",
       "<td>0.3263889</td>\n",
       "<td>0.7916667</td>\n",
       "<td>552.7777778</td>\n",
       "<td>691.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0947565</td>\n",
       "<td>1.8055556</td>\n",
       "<td>5.8796296</td>\n",
       "<td>0.1733333</td>\n",
       "<td>0.5644444</td>\n",
       "<td>0.0902778</td>\n",
       "<td>0.8819444</td>\n",
       "<td>80.5555556</td>\n",
       "<td>487.9629630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0601720</td>\n",
       "<td>1.25</td>\n",
       "<td>4.7222222</td>\n",
       "<td>0.12</td>\n",
       "<td>0.4533333</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.9444444</td>\n",
       "<td>25.0</td>\n",
       "<td>372.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0341271</td>\n",
       "<td>0.2777778</td>\n",
       "<td>3.2407407</td>\n",
       "<td>0.0266667</td>\n",
       "<td>0.3111111</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.9722222</td>\n",
       "<td>-72.2222222</td>\n",
       "<td>224.0740741</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0219989</td>\n",
       "<td>0.0694444</td>\n",
       "<td>2.4479167</td>\n",
       "<td>0.0066667</td>\n",
       "<td>0.235</td>\n",
       "<td>0.0069444</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-93.0555556</td>\n",
       "<td>144.7916667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0126700</td>\n",
       "<td>0.2083333</td>\n",
       "<td>2.0</td>\n",
       "<td>0.02</td>\n",
       "<td>0.192</td>\n",
       "<td>0.0208333</td>\n",
       "<td>1.0</td>\n",
       "<td>-79.1666667</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0118427</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.16</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0118073</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1371429</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0117764</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0117378</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0116789</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.655984           10.4167    10.4167            1                1                           0.104167        0.104167                   941.667   941.667\n",
       "    2        0.02                        0.645448           8.33333    9.375              0.8              0.9                         0.0833333       0.1875                     733.333   837.5\n",
       "    3        0.03                        0.635954           9.72222    9.49074            0.933333         0.911111                    0.0972222       0.284722                   872.222   849.074\n",
       "    4        0.04                        0.627766           8.33333    9.20139            0.8              0.883333                    0.0833333       0.368056                   733.333   820.139\n",
       "    5        0.05                        0.61373            9.72222    9.30556            0.933333         0.893333                    0.0972222       0.465278                   872.222   830.556\n",
       "    6        0.1                         0.238954           6.52778    7.91667            0.626667         0.76                        0.326389        0.791667                   552.778   691.667\n",
       "    7        0.15                        0.0947565          1.80556    5.87963            0.173333         0.564444                    0.0902778       0.881944                   80.5556   487.963\n",
       "    8        0.2                         0.060172           1.25       4.72222            0.12             0.453333                    0.0625          0.944444                   25        372.222\n",
       "    9        0.3                         0.0341271          0.277778   3.24074            0.0266667        0.311111                    0.0277778       0.972222                   -72.2222  224.074\n",
       "    10       0.4                         0.0219989          0.0694444  2.44792            0.00666667       0.235                       0.00694444      0.979167                   -93.0556  144.792\n",
       "    11       0.5                         0.01267            0.208333   2                  0.02             0.192                       0.0208333       1                          -79.1667  100\n",
       "    12       0.6                         0.0118427          0          1.66667            0                0.16                        0               1                          -100      66.6667\n",
       "    13       0.7                         0.0118073          0          1.42857            0                0.137143                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0117764          0          1.25               0                0.12                        0               1                          -100      25\n",
       "    15       0.9                         0.0117378          0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0116789          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test data performance metrics\n",
    "model.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1496736115661_10\n",
      "Status of Neuron Layers: predicting pers_loan, 2-class classification, multinomial distribution, CrossEntropy loss, 6,202 weights/biases, 79.3 KB, 385,000 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>19</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2117783</td>\n",
       "<td>0.4102108</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0376196</td>\n",
       "<td>1.1713943</td>\n",
       "<td>0.0020606</td>\n",
       "<td>1.1227937</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0094161</td>\n",
       "<td>0.0214251</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0032480</td>\n",
       "<td>0.5070341</td>\n",
       "<td>-0.0118283</td>\n",
       "<td>1.2967100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>50</td>\n",
       "<td>TanhDropout</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0508906</td>\n",
       "<td>0.1332909</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0016964</td>\n",
       "<td>0.1918201</td>\n",
       "<td>0.0292983</td>\n",
       "<td>0.4668208</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0001</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0193523</td>\n",
       "<td>0.1176573</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0234441</td>\n",
       "<td>0.4128304</td>\n",
       "<td>-0.0130815</td>\n",
       "<td>0.9297132</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type         dropout    l1      l2    mean_rate         rate_rms         momentum    mean_weight        weight_rms      mean_bias         bias_rms\n",
       "--  -------  -------  -----------  ---------  ------  ----  ----------------  ---------------  ----------  -----------------  --------------  ----------------  --------------\n",
       "    1        19       Input        10.0\n",
       "    2        50       TanhDropout  50.0       0.0001  0.0   0.211778286684    0.410210847855   0.0         0.0376195660461    1.17139434814   0.00206062811495  1.12279367447\n",
       "    3        50       TanhDropout  50.0       0.0001  0.0   0.00941606880827  0.0214250609279  0.0         -0.00324799562058  0.507034063339  -0.0118282645905  1.29671001434\n",
       "    4        50       TanhDropout  50.0       0.0001  0.0   0.0508905532768   0.133290946484   0.0         -0.00169639947334  0.191820085049  0.029298252369    0.466820836067\n",
       "    5        2        Softmax                 0.0001  0.0   0.0193523469602   0.117657274008   0.0         -0.0234440551466   0.412830352783  -0.0130814714363  0.929713249207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0374867531657\n",
      "RMSE: 0.19361496111\n",
      "LogLoss: 0.134131204218\n",
      "Mean Per-Class Error: 0.0847687526338\n",
      "AUC: 0.970069720366\n",
      "Gini: 0.940139440732\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30876653834: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>3113.0</td>\n",
       "<td>51.0</td>\n",
       "<td>0.0161</td>\n",
       "<td> (51.0/3164.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>79.0</td>\n",
       "<td>257.0</td>\n",
       "<td>0.2351</td>\n",
       "<td> (79.0/336.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3192.0</td>\n",
       "<td>308.0</td>\n",
       "<td>0.0371</td>\n",
       "<td> (130.0/3500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      3113  51   0.0161   (51.0/3164.0)\n",
       "1      79    257  0.2351   (79.0/336.0)\n",
       "Total  3192  308  0.0371   (130.0/3500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7981366</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.8164937</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4623582</td>\n",
       "<td>0.8308157</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3156085</td>\n",
       "<td>0.9628571</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.6581360</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0124035</td>\n",
       "<td>1.0</td>\n",
       "<td>392.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.6581360</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3087665</td>\n",
       "<td>0.7786189</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0736977</td>\n",
       "<td>0.9086599</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0962572</td>\n",
       "<td>0.9152312</td>\n",
       "<td>242.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.308767     0.798137  146\n",
       "max f2                       0.0962572    0.816494  242\n",
       "max f0point5                 0.462358     0.830816  100\n",
       "max accuracy                 0.315608     0.962857  144\n",
       "max precision                0.658136     1         0\n",
       "max recall                   0.0124035    1         392\n",
       "max specificity              0.658136     1         0\n",
       "max absolute_mcc             0.308767     0.778619  146\n",
       "max min_per_class_accuracy   0.0736977    0.90866   269\n",
       "max mean_per_class_accuracy  0.0962572    0.915231  242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.6563358</td>\n",
       "<td>10.4166667</td>\n",
       "<td>10.4166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1041667</td>\n",
       "<td>0.1041667</td>\n",
       "<td>941.6666667</td>\n",
       "<td>941.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6523158</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.8214286</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.1964286</td>\n",
       "<td>822.6190476</td>\n",
       "<td>882.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6390291</td>\n",
       "<td>8.6309524</td>\n",
       "<td>9.4246032</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.9047619</td>\n",
       "<td>0.0863095</td>\n",
       "<td>0.2827381</td>\n",
       "<td>763.0952381</td>\n",
       "<td>842.4603175</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6292032</td>\n",
       "<td>10.1190476</td>\n",
       "<td>9.5982143</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9214286</td>\n",
       "<td>0.1011905</td>\n",
       "<td>0.3839286</td>\n",
       "<td>911.9047619</td>\n",
       "<td>859.8214286</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.6063924</td>\n",
       "<td>8.9285714</td>\n",
       "<td>9.4642857</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9085714</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.4732143</td>\n",
       "<td>792.8571429</td>\n",
       "<td>846.4285714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.1960377</td>\n",
       "<td>6.4880952</td>\n",
       "<td>7.9761905</td>\n",
       "<td>0.6228571</td>\n",
       "<td>0.7657143</td>\n",
       "<td>0.3244048</td>\n",
       "<td>0.7976190</td>\n",
       "<td>548.8095238</td>\n",
       "<td>697.6190476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0842467</td>\n",
       "<td>1.9642857</td>\n",
       "<td>5.9722222</td>\n",
       "<td>0.1885714</td>\n",
       "<td>0.5733333</td>\n",
       "<td>0.0982143</td>\n",
       "<td>0.8958333</td>\n",
       "<td>96.4285714</td>\n",
       "<td>497.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0588496</td>\n",
       "<td>0.8928571</td>\n",
       "<td>4.7023810</td>\n",
       "<td>0.0857143</td>\n",
       "<td>0.4514286</td>\n",
       "<td>0.0446429</td>\n",
       "<td>0.9404762</td>\n",
       "<td>-10.7142857</td>\n",
       "<td>370.2380952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0342866</td>\n",
       "<td>0.1785714</td>\n",
       "<td>3.1944444</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.3066667</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9583333</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>219.4444444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0215800</td>\n",
       "<td>0.2083333</td>\n",
       "<td>2.4479167</td>\n",
       "<td>0.02</td>\n",
       "<td>0.235</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-79.1666667</td>\n",
       "<td>144.7916667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0126327</td>\n",
       "<td>0.1785714</td>\n",
       "<td>1.9940476</td>\n",
       "<td>0.0171429</td>\n",
       "<td>0.1914286</td>\n",
       "<td>0.0178571</td>\n",
       "<td>0.9970238</td>\n",
       "<td>-82.1428571</td>\n",
       "<td>99.4047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0118444</td>\n",
       "<td>0.0297619</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0028571</td>\n",
       "<td>0.16</td>\n",
       "<td>0.0029762</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.0238095</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0118066</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1371429</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0117779</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0117396</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0116798</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.656336           10.4167    10.4167            1                1                           0.104167        0.104167                   941.667   941.667\n",
       "    2        0.02                        0.652316           9.22619    9.82143            0.885714         0.942857                    0.0922619       0.196429                   822.619   882.143\n",
       "    3        0.03                        0.639029           8.63095    9.4246             0.828571         0.904762                    0.0863095       0.282738                   763.095   842.46\n",
       "    4        0.04                        0.629203           10.119     9.59821            0.971429         0.921429                    0.10119         0.383929                   911.905   859.821\n",
       "    5        0.05                        0.606392           8.92857    9.46429            0.857143         0.908571                    0.0892857       0.473214                   792.857   846.429\n",
       "    6        0.1                         0.196038           6.4881     7.97619            0.622857         0.765714                    0.324405        0.797619                   548.81    697.619\n",
       "    7        0.15                        0.0842467          1.96429    5.97222            0.188571         0.573333                    0.0982143       0.895833                   96.4286   497.222\n",
       "    8        0.2                         0.0588496          0.892857   4.70238            0.0857143        0.451429                    0.0446429       0.940476                   -10.7143  370.238\n",
       "    9        0.3                         0.0342866          0.178571   3.19444            0.0171429        0.306667                    0.0178571       0.958333                   -82.1429  219.444\n",
       "    10       0.4                         0.02158            0.208333   2.44792            0.02             0.235                       0.0208333       0.979167                   -79.1667  144.792\n",
       "    11       0.5                         0.0126327          0.178571   1.99405            0.0171429        0.191429                    0.0178571       0.997024                   -82.1429  99.4048\n",
       "    12       0.6                         0.0118444          0.0297619  1.66667            0.00285714       0.16                        0.00297619      1                          -97.0238  66.6667\n",
       "    13       0.7                         0.0118066          0          1.42857            0                0.137143                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0117779          0          1.25               0                0.12                        0               1                          -100      25\n",
       "    15       0.9                         0.0117396          0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0116798          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0376753629732\n",
      "RMSE: 0.194101424449\n",
      "LogLoss: 0.135341518619\n",
      "Mean Per-Class Error: 0.0929203539823\n",
      "AUC: 0.9607324401\n",
      "Gini: 0.9214648802\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.388100194917: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>3094.0</td>\n",
       "<td>70.0</td>\n",
       "<td>0.0221</td>\n",
       "<td> (70.0/3164.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>73.0</td>\n",
       "<td>263.0</td>\n",
       "<td>0.2173</td>\n",
       "<td> (73.0/336.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3167.0</td>\n",
       "<td>333.0</td>\n",
       "<td>0.0409</td>\n",
       "<td> (143.0/3500.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      3094  70   0.0221   (70.0/3164.0)\n",
       "1      73    263  0.2173   (73.0/336.0)\n",
       "Total  3167  333  0.0409   (143.0/3500.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.7862481</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2383975</td>\n",
       "<td>0.7948140</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5007413</td>\n",
       "<td>0.8005618</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.9591429</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7798890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0106412</td>\n",
       "<td>1.0</td>\n",
       "<td>391.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7798890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3881002</td>\n",
       "<td>0.7636708</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1079401</td>\n",
       "<td>0.9039191</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0839398</td>\n",
       "<td>0.9070796</td>\n",
       "<td>301.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.3881       0.786248  153\n",
       "max f2                       0.238397     0.794814  212\n",
       "max f0point5                 0.500741     0.800562  115\n",
       "max accuracy                 0.3881       0.959143  153\n",
       "max precision                0.779889     1         0\n",
       "max recall                   0.0106412    1         391\n",
       "max specificity              0.779889     1         0\n",
       "max absolute_mcc             0.3881       0.763671  153\n",
       "max min_per_class_accuracy   0.10794      0.903919  284\n",
       "max mean_per_class_accuracy  0.0839398    0.90708   301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  9.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.7334891</td>\n",
       "<td>9.8214286</td>\n",
       "<td>9.8214286</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.0982143</td>\n",
       "<td>0.0982143</td>\n",
       "<td>882.1428571</td>\n",
       "<td>882.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.6928595</td>\n",
       "<td>8.9285714</td>\n",
       "<td>9.375</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.1875</td>\n",
       "<td>792.8571429</td>\n",
       "<td>837.5</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.6479753</td>\n",
       "<td>8.3333333</td>\n",
       "<td>9.0277778</td>\n",
       "<td>0.8</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.2708333</td>\n",
       "<td>733.3333333</td>\n",
       "<td>802.7777778</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.6220193</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.0773810</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8714286</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.3630952</td>\n",
       "<td>822.6190476</td>\n",
       "<td>807.7380952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.5970436</td>\n",
       "<td>9.2261905</td>\n",
       "<td>9.1071429</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8742857</td>\n",
       "<td>0.0922619</td>\n",
       "<td>0.4553571</td>\n",
       "<td>822.6190476</td>\n",
       "<td>810.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3399548</td>\n",
       "<td>6.7261905</td>\n",
       "<td>7.9166667</td>\n",
       "<td>0.6457143</td>\n",
       "<td>0.76</td>\n",
       "<td>0.3363095</td>\n",
       "<td>0.7916667</td>\n",
       "<td>572.6190476</td>\n",
       "<td>691.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.1530605</td>\n",
       "<td>1.7261905</td>\n",
       "<td>5.8531746</td>\n",
       "<td>0.1657143</td>\n",
       "<td>0.5619048</td>\n",
       "<td>0.0863095</td>\n",
       "<td>0.8779762</td>\n",
       "<td>72.6190476</td>\n",
       "<td>485.3174603</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0737658</td>\n",
       "<td>1.0119048</td>\n",
       "<td>4.6428571</td>\n",
       "<td>0.0971429</td>\n",
       "<td>0.4457143</td>\n",
       "<td>0.0505952</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.1904762</td>\n",
       "<td>364.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0289900</td>\n",
       "<td>0.2678571</td>\n",
       "<td>3.1845238</td>\n",
       "<td>0.0257143</td>\n",
       "<td>0.3057143</td>\n",
       "<td>0.0267857</td>\n",
       "<td>0.9553571</td>\n",
       "<td>-73.2142857</td>\n",
       "<td>218.4523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0138734</td>\n",
       "<td>0.1488095</td>\n",
       "<td>2.4255952</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.2328571</td>\n",
       "<td>0.0148810</td>\n",
       "<td>0.9702381</td>\n",
       "<td>-85.1190476</td>\n",
       "<td>142.5595238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0127652</td>\n",
       "<td>0.0892857</td>\n",
       "<td>1.9583333</td>\n",
       "<td>0.0085714</td>\n",
       "<td>0.188</td>\n",
       "<td>0.0089286</td>\n",
       "<td>0.9791667</td>\n",
       "<td>-91.0714286</td>\n",
       "<td>95.8333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0116401</td>\n",
       "<td>0.0595238</td>\n",
       "<td>1.6418651</td>\n",
       "<td>0.0057143</td>\n",
       "<td>0.1576190</td>\n",
       "<td>0.0059524</td>\n",
       "<td>0.9851190</td>\n",
       "<td>-94.0476190</td>\n",
       "<td>64.1865079</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0110488</td>\n",
       "<td>0.1190476</td>\n",
       "<td>1.4243197</td>\n",
       "<td>0.0114286</td>\n",
       "<td>0.1367347</td>\n",
       "<td>0.0119048</td>\n",
       "<td>0.9970238</td>\n",
       "<td>-88.0952381</td>\n",
       "<td>42.4319728</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0095469</td>\n",
       "<td>0.0297619</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0028571</td>\n",
       "<td>0.12</td>\n",
       "<td>0.0029762</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.0238095</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0077356</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1066667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0073608</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.733489           9.82143    9.82143            0.942857         0.942857                    0.0982143       0.0982143                  882.143   882.143\n",
       "    2        0.02                        0.69286            8.92857    9.375              0.857143         0.9                         0.0892857       0.1875                     792.857   837.5\n",
       "    3        0.03                        0.647975           8.33333    9.02778            0.8              0.866667                    0.0833333       0.270833                   733.333   802.778\n",
       "    4        0.04                        0.622019           9.22619    9.07738            0.885714         0.871429                    0.0922619       0.363095                   822.619   807.738\n",
       "    5        0.05                        0.597044           9.22619    9.10714            0.885714         0.874286                    0.0922619       0.455357                   822.619   810.714\n",
       "    6        0.1                         0.339955           6.72619    7.91667            0.645714         0.76                        0.33631         0.791667                   572.619   691.667\n",
       "    7        0.15                        0.153061           1.72619    5.85317            0.165714         0.561905                    0.0863095       0.877976                   72.619    485.317\n",
       "    8        0.2                         0.0737658          1.0119     4.64286            0.0971429        0.445714                    0.0505952       0.928571                   1.19048   364.286\n",
       "    9        0.3                         0.02899            0.267857   3.18452            0.0257143        0.305714                    0.0267857       0.955357                   -73.2143  218.452\n",
       "    10       0.4                         0.0138734          0.14881    2.4256             0.0142857        0.232857                    0.014881        0.970238                   -85.119   142.56\n",
       "    11       0.5                         0.0127652          0.0892857  1.95833            0.00857143       0.188                       0.00892857      0.979167                   -91.0714  95.8333\n",
       "    12       0.6                         0.0116401          0.0595238  1.64187            0.00571429       0.157619                    0.00595238      0.985119                   -94.0476  64.1865\n",
       "    13       0.7                         0.0110488          0.119048   1.42432            0.0114286        0.136735                    0.0119048       0.997024                   -88.0952  42.432\n",
       "    14       0.8                         0.00954687         0.0297619  1.25               0.00285714       0.12                        0.00297619      1                          -97.0238  25\n",
       "    15       0.9                         0.00773562         0          1.11111            0                0.106667                    0               1                          -100      11.1111\n",
       "    16       1                           0.0073608          0          1                  0                0.096                       0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9624398</td>\n",
       "<td>0.0045850</td>\n",
       "<td>0.9733893</td>\n",
       "<td>0.9562683</td>\n",
       "<td>0.9602357</td>\n",
       "<td>0.965847</td>\n",
       "<td>0.9564586</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9661146</td>\n",
       "<td>0.0069172</td>\n",
       "<td>0.9723753</td>\n",
       "<td>0.9467847</td>\n",
       "<td>0.9714912</td>\n",
       "<td>0.9718502</td>\n",
       "<td>0.968072</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0375602</td>\n",
       "<td>0.0045850</td>\n",
       "<td>0.0266106</td>\n",
       "<td>0.0437318</td>\n",
       "<td>0.0397644</td>\n",
       "<td>0.0341530</td>\n",
       "<td>0.0435414</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>26.2</td>\n",
       "<td>2.8774989</td>\n",
       "<td>19.0</td>\n",
       "<td>30.0</td>\n",
       "<td>27.0</td>\n",
       "<td>25.0</td>\n",
       "<td>30.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.8141792</td>\n",
       "<td>0.0242135</td>\n",
       "<td>0.875</td>\n",
       "<td>0.7836990</td>\n",
       "<td>0.8288044</td>\n",
       "<td>0.7939189</td>\n",
       "<td>0.7894737</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7965801</td>\n",
       "<td>0.0261990</td>\n",
       "<td>0.8549618</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.8187919</td>\n",
       "<td>0.789916</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7800731</td>\n",
       "<td>0.0298707</td>\n",
       "<td>0.8358209</td>\n",
       "<td>0.755287</td>\n",
       "<td>0.8090186</td>\n",
       "<td>0.7859532</td>\n",
       "<td>0.7142857</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>9.936483</td>\n",
       "<td>1.069964</td>\n",
       "<td>10.5</td>\n",
       "<td>10.238806</td>\n",
       "<td>7.6578946</td>\n",
       "<td>12.2</td>\n",
       "<td>9.085714</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.1356553</td>\n",
       "<td>0.0087051</td>\n",
       "<td>0.1311911</td>\n",
       "<td>0.1511206</td>\n",
       "<td>0.1465405</td>\n",
       "<td>0.1163249</td>\n",
       "<td>0.1330990</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2303859</td>\n",
       "<td>0.0327208</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.2537313</td>\n",
       "<td>0.1973684</td>\n",
       "<td>0.2166667</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.7768043</td>\n",
       "<td>0.0278982</td>\n",
       "<td>0.8410789</td>\n",
       "<td>0.7455322</td>\n",
       "<td>0.7966734</td>\n",
       "<td>0.7713623</td>\n",
       "<td>0.729375</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8762450</td>\n",
       "<td>0.0167753</td>\n",
       "<td>0.9063467</td>\n",
       "<td>0.8626335</td>\n",
       "<td>0.8913655</td>\n",
       "<td>0.8827381</td>\n",
       "<td>0.838141</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1237550</td>\n",
       "<td>0.0167753</td>\n",
       "<td>0.0936533</td>\n",
       "<td>0.1373665</td>\n",
       "<td>0.1086345</td>\n",
       "<td>0.1172619</td>\n",
       "<td>0.1618590</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0377755</td>\n",
       "<td>0.0025824</td>\n",
       "<td>0.0363035</td>\n",
       "<td>0.0407072</td>\n",
       "<td>0.0421197</td>\n",
       "<td>0.0316946</td>\n",
       "<td>0.0380525</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.8265896</td>\n",
       "<td>0.0245298</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.7936508</td>\n",
       "<td>0.8356164</td>\n",
       "<td>0.7966102</td>\n",
       "<td>0.8181818</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5652950</td>\n",
       "<td>0.0115579</td>\n",
       "<td>0.5786878</td>\n",
       "<td>0.5380936</td>\n",
       "<td>0.5762654</td>\n",
       "<td>0.5788015</td>\n",
       "<td>0.5546271</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7696142</td>\n",
       "<td>0.0327208</td>\n",
       "<td>0.8235294</td>\n",
       "<td>0.7462686</td>\n",
       "<td>0.8026316</td>\n",
       "<td>0.7833334</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1941252</td>\n",
       "<td>0.0067415</td>\n",
       "<td>0.1905349</td>\n",
       "<td>0.2017602</td>\n",
       "<td>0.2052308</td>\n",
       "<td>0.1780298</td>\n",
       "<td>0.1950705</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9828758</td>\n",
       "<td>0.0025304</td>\n",
       "<td>0.9891641</td>\n",
       "<td>0.9789984</td>\n",
       "<td>0.9800995</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9839743</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.96244    0.00458501  0.973389      0.956268      0.960236      0.965847      0.956459\n",
       "auc                      0.966115   0.00691722  0.972375      0.946785      0.971491      0.97185       0.968072\n",
       "err                      0.0375602  0.00458501  0.0266106     0.0437318     0.0397644     0.034153      0.0435414\n",
       "err_count                26.2       2.8775      19            30            27            25            30\n",
       "f0point5                 0.814179   0.0242135   0.875         0.783699      0.828804      0.793919      0.789474\n",
       "f1                       0.79658    0.026199    0.854962      0.769231      0.818792      0.789916      0.75\n",
       "f2                       0.780073   0.0298707   0.835821      0.755287      0.809019      0.785953      0.714286\n",
       "lift_top_group           9.93648    1.06996     10.5          10.2388       7.65789       12.2          9.08571\n",
       "logloss                  0.135655   0.00870512  0.131191      0.151121      0.146541      0.116325      0.133099\n",
       "max_per_class_error      0.230386   0.0327208   0.176471      0.253731      0.197368      0.216667      0.307692\n",
       "mcc                      0.776804   0.0278982   0.841079      0.745532      0.796673      0.771362      0.729375\n",
       "mean_per_class_accuracy  0.876245   0.0167753   0.906347      0.862634      0.891366      0.882738      0.838141\n",
       "mean_per_class_error     0.123755   0.0167753   0.0936533     0.137366      0.108634      0.117262      0.161859\n",
       "mse                      0.0377755  0.0025824   0.0363035     0.0407072     0.0421197     0.0316946     0.0380525\n",
       "precision                0.82659    0.0245298   0.888889      0.793651      0.835616      0.79661       0.818182\n",
       "r2                       0.565295   0.0115579   0.578688      0.538094      0.576265      0.578801      0.554627\n",
       "recall                   0.769614   0.0327208   0.823529      0.746269      0.802632      0.783333      0.692308\n",
       "rmse                     0.194125   0.00674149  0.190535      0.20176       0.205231      0.17803       0.195071\n",
       "specificity              0.982876   0.00253039  0.989164      0.978998      0.9801        0.982143      0.983974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:25</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:27</td>\n",
       "<td>51.888 sec</td>\n",
       "<td>28340 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>35000.0</td>\n",
       "<td>0.2046760</td>\n",
       "<td>0.1459836</td>\n",
       "<td>0.9594122</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.0491429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:33</td>\n",
       "<td>58.038 sec</td>\n",
       "<td>28649 obs/sec</td>\n",
       "<td>60.0</td>\n",
       "<td>6</td>\n",
       "<td>210000.0</td>\n",
       "<td>0.1992744</td>\n",
       "<td>0.1417528</td>\n",
       "<td>0.9661853</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.034</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-06-06 14:16:39</td>\n",
       "<td> 1 min  4.120 sec</td>\n",
       "<td>28819 obs/sec</td>\n",
       "<td>110.0</td>\n",
       "<td>11</td>\n",
       "<td>385000.0</td>\n",
       "<td>0.1936150</td>\n",
       "<td>0.1341312</td>\n",
       "<td>0.9700697</td>\n",
       "<td>10.4166667</td>\n",
       "<td>0.0371429</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2017-06-06 14:16:25  0.000 sec                           0         0             0          nan              nan                 nan             nan              nan\n",
       "    2017-06-06 14:16:27  51.888 sec        28340 obs/sec     10        1             35000      0.204676         0.145984            0.959412        10.4167          0.0491429\n",
       "    2017-06-06 14:16:33  58.038 sec        28649 obs/sec     60        6             210000     0.199274         0.141753            0.966185        10.4167          0.034\n",
       "    2017-06-06 14:16:39  1 min  4.120 sec  28819 obs/sec     110       11            385000     0.193615         0.134131            0.97007         10.4167          0.0371429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>cd_account.1</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2904788</td></tr>\n",
       "<tr><td>income</td>\n",
       "<td>0.3277385</td>\n",
       "<td>0.3277385</td>\n",
       "<td>0.0952011</td></tr>\n",
       "<tr><td>education.2</td>\n",
       "<td>0.3205053</td>\n",
       "<td>0.3205053</td>\n",
       "<td>0.0931000</td></tr>\n",
       "<tr><td>education.3</td>\n",
       "<td>0.3178874</td>\n",
       "<td>0.3178874</td>\n",
       "<td>0.0923395</td></tr>\n",
       "<tr><td>cd_account.0</td>\n",
       "<td>0.2599115</td>\n",
       "<td>0.2599115</td>\n",
       "<td>0.0754988</td></tr>\n",
       "<tr><td>credit_card.1</td>\n",
       "<td>0.2311025</td>\n",
       "<td>0.2311025</td>\n",
       "<td>0.0671304</td></tr>\n",
       "<tr><td>ccavg</td>\n",
       "<td>0.2152246</td>\n",
       "<td>0.2152246</td>\n",
       "<td>0.0625182</td></tr>\n",
       "<tr><td>online.1</td>\n",
       "<td>0.1669591</td>\n",
       "<td>0.1669591</td>\n",
       "<td>0.0484981</td></tr>\n",
       "<tr><td>education.1</td>\n",
       "<td>0.1054023</td>\n",
       "<td>0.1054023</td>\n",
       "<td>0.0306171</td></tr>\n",
       "<tr><td>credit_card.0</td>\n",
       "<td>0.1011096</td>\n",
       "<td>0.1011096</td>\n",
       "<td>0.0293702</td></tr>\n",
       "<tr><td>online.0</td>\n",
       "<td>0.0934615</td>\n",
       "<td>0.0934615</td>\n",
       "<td>0.0271486</td></tr>\n",
       "<tr><td>sec_amount</td>\n",
       "<td>0.0844852</td>\n",
       "<td>0.0844852</td>\n",
       "<td>0.0245411</td></tr>\n",
       "<tr><td>family</td>\n",
       "<td>0.0810655</td>\n",
       "<td>0.0810655</td>\n",
       "<td>0.0235478</td></tr>\n",
       "<tr><td>mortgage</td>\n",
       "<td>0.0698077</td>\n",
       "<td>0.0698077</td>\n",
       "<td>0.0202777</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>0.0679318</td>\n",
       "<td>0.0679318</td>\n",
       "<td>0.0197327</td></tr>\n",
       "<tr><td>education.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>credit_card.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>cd_account.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>online.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                 relative_importance    scaled_importance    percentage\n",
       "-----------------------  ---------------------  -------------------  ------------\n",
       "cd_account.1             1                      1                    0.290479\n",
       "income                   0.327738               0.327738             0.0952011\n",
       "education.2              0.320505               0.320505             0.0931\n",
       "education.3              0.317887               0.317887             0.0923395\n",
       "cd_account.0             0.259912               0.259912             0.0754988\n",
       "credit_card.1            0.231102               0.231102             0.0671304\n",
       "ccavg                    0.215225               0.215225             0.0625182\n",
       "online.1                 0.166959               0.166959             0.0484981\n",
       "education.1              0.105402               0.105402             0.0306171\n",
       "credit_card.0            0.10111                0.10111              0.0293702\n",
       "online.0                 0.0934615              0.0934615            0.0271486\n",
       "sec_amount               0.0844852              0.0844852            0.0245411\n",
       "family                   0.0810655              0.0810655            0.0235478\n",
       "mortgage                 0.0698077              0.0698077            0.0202777\n",
       "age                      0.0679318              0.0679318            0.0197327\n",
       "education.missing(NA)    0                      0                    0\n",
       "credit_card.missing(NA)  0                      0                    0\n",
       "cd_account.missing(NA)   0                      0                    0\n",
       "online.missing(NA)       0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ODeepLearningEstimator.deepfeatures of >"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variable importan"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
